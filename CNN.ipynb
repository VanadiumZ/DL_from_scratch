{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionDataset(Dataset):\n",
    "    '''\n",
    "    定义Dataset:\n",
    "    - 用于加载训练和测试数据，请勿改动\n",
    "    - 返回一张图片(3维Tensor)以及对应的标签(0-9)\n",
    "    '''\n",
    "    def __init__(self,datadir,transform,is_train = True):\n",
    "        super().__init__()\n",
    "        self.datadir = datadir\n",
    "        self.img,self.label = self.load_data(self.datadir,is_train = is_train)\n",
    "        self.len_data = len(self.img)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        return self.transform(self.img[index]), self.label[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len_data\n",
    "    \n",
    "    def load_data(self,datadir,is_train):\n",
    "        dirname = os.path.join(datadir)\n",
    "        files = ['train-labels-idx1-ubyte.gz', 'train-images-idx3-ubyte.gz',\n",
    "            't10k-labels-idx1-ubyte.gz', 't10k-images-idx3-ubyte.gz']\n",
    "\n",
    "        paths = []\n",
    "        for fname in files:\n",
    "            paths.append(os.path.join(dirname,fname))\n",
    "        if is_train:\n",
    "\n",
    "            with gzip.open(paths[0], 'rb') as lbpath:\n",
    "                label = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n",
    "            with gzip.open(paths[1], 'rb') as imgpath:\n",
    "                img = np.frombuffer(imgpath.read(), np.uint8,\n",
    "                                   offset=16).reshape(len(label), 28, 28)\n",
    "        else:\n",
    "            with gzip.open(paths[2], 'rb') as lbpath:\n",
    "                label = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n",
    "\n",
    "            with gzip.open(paths[3], 'rb') as imgpath:\n",
    "                img = np.frombuffer(imgpath.read(), np.uint8,\n",
    "                                      offset=16).reshape(len(label), 28, 28)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMnistModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        ***********请在此写入你的代码**********\n",
    "        定义模型\n",
    "        '''\n",
    "        super(FashionMnistModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
    "        self.conv2 = nn.Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(in_features=800, out_features=500, bias=True)\n",
    "        self.fc2 = nn.Linear(in_features=500, out_features=10, bias=True)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        *********请在此处输入你的代码*********\n",
    "        输入：input, 它的size是(batch_size, img_h, img_w, img_c)\n",
    "        输出（返回值）：output(预测值)，hidden(隐藏层的值)\n",
    "            * output的size是(batch_size, num_label)\n",
    "            \n",
    "        定义模型函数：\n",
    "            * 将输入经过卷积层和激活函数\n",
    "            * 使用pooling降低通道数\n",
    "            * 对卷积层的输出做适当的维度变换\n",
    "            * 用线性层将output映射到num_label的维度上\n",
    "            * 返回output\n",
    "        '''\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 50 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        创建模型和优化器，设置模型超参数\n",
    "        * 参数\n",
    "            * learning_rate\n",
    "            * epoches\n",
    "            * model_save_path\n",
    "            * device: cuda or cpu\n",
    "        * 模型\n",
    "            * 创建FashionMnistModel的实例，命名为model\n",
    "            * 定义optimizer\n",
    "            * 定义loss function\n",
    "        '''\n",
    "        self.lr = 0.01\n",
    "        self.epoches = 20\n",
    "        self.model_save_path = './model'\n",
    "        # 指定训练的device，优先使用GPU，GPU不可用时加载CPU\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  \n",
    "        self.model = FashionMnistModel().to(self.device)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        self.loss_function = nn.CrossEntropyLoss()\n",
    "    def _save_model(self, epoch):\n",
    "        \"\"\"\n",
    "        保存模型，用于训练时保存指定epoch的模型\n",
    "        \"\"\"\n",
    "        print('[INFO] Saving to %s/%s.pth' % (self.model_save_path, epoch))\n",
    "        torch.save(self.model.state_dict(), '%s/%s.pth' % (self.model_save_path, epoch))\n",
    "        \n",
    "    def _load_model(self, epoch):\n",
    "        \"\"\"\n",
    "        加载模型，用于加载指定epoch的模型。\n",
    "        目前代码中没有用到。\n",
    "        可以在训练到一半但中断了之后，自行修改代码，从最近的epoch加载，然后继续训练，以节省时间。\n",
    "        或者训练完毕后，下次再跑程序，就直接加载模型，省去训练时间。\n",
    "        \"\"\"\n",
    "        print('[INFO] Loading from %s_%s.pth' % (self.model_save_path, epoch))\n",
    "        self.model.load_state_dict(torch.load('%s/%s.pth' % (self.model_save_path, epoch), map_location=self.device))\n",
    "        \n",
    "    def train(self,train_loader,test_loader):\n",
    "        '''\n",
    "        训练函数\n",
    "        '''\n",
    "        self.model.train()\n",
    "        for epoch in range(self.epoches):\n",
    "            loss_list = []\n",
    "            for batch_idx, (data, target) in enumerate(train_loader):\n",
    "                data, target = data.to(self.device), target.long().to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.model(data)\n",
    "                loss = self.loss_function(output, target)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                loss_list.append(loss.item())\n",
    "                if batch_idx % 50 == 0:\n",
    "                    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                               100. * batch_idx / len(train_loader), loss.item()))\n",
    "            self.test(test_loader)\n",
    "            # 保存模型参数\n",
    "            if (epoch+1) % 5 == 0:\n",
    "                self._save_model(epoch+1)\n",
    "    def test(self,test_loader):\n",
    "        '''\n",
    "        检验模型测试集上的效果\n",
    "        '''\n",
    "        self.model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(self.device), target.long().to(self.device)\n",
    "                output = self.model(data)\n",
    "                test_loss += self.loss_function(output, target).item()  # sum up batch loss\n",
    "                pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, correct, len(test_loader.dataset),\n",
    "            100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义data loader\n",
    "train_dataset = FashionDataset('data',\n",
    "                         transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                         ])\n",
    "                        )\n",
    "                             \n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=320, shuffle=True, num_workers= 0)\n",
    "\n",
    "test_dataset = FashionDataset('data',\n",
    "                         transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                         ]),\n",
    "                        is_train = False\n",
    "                        )\n",
    "test_loader = DataLoader(test_dataset,batch_size=32, shuffle=False, num_workers= 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.306559\n",
      "Train Epoch: 0 [16000/60000 (27%)]\tLoss: 0.537002\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.406788\n",
      "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.412198\n",
      "\n",
      "Test set: Average loss: 0.0124, Accuracy: 8551/10000 (86%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.489376\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.412354\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.282215\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.336242\n",
      "\n",
      "Test set: Average loss: 0.0117, Accuracy: 8610/10000 (86%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.333851\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.312758\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.354810\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.295404\n",
      "\n",
      "Test set: Average loss: 0.0110, Accuracy: 8696/10000 (87%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.233022\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.294482\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.254706\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.309709\n",
      "\n",
      "Test set: Average loss: 0.0103, Accuracy: 8808/10000 (88%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.201903\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.280915\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.246209\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.228287\n",
      "\n",
      "Test set: Average loss: 0.0110, Accuracy: 8708/10000 (87%)\n",
      "\n",
      "[INFO] Saving to ./model/5.pth\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.206163\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.353606\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.256834\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.289053\n",
      "\n",
      "Test set: Average loss: 0.0105, Accuracy: 8794/10000 (88%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.251349\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.239305\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.239916\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.302715\n",
      "\n",
      "Test set: Average loss: 0.0107, Accuracy: 8776/10000 (88%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.273308\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.230831\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.292221\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.348682\n",
      "\n",
      "Test set: Average loss: 0.0106, Accuracy: 8796/10000 (88%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.197169\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.224235\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.263484\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.190532\n",
      "\n",
      "Test set: Average loss: 0.0107, Accuracy: 8860/10000 (89%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.167626\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.300489\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.182727\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.239429\n",
      "\n",
      "Test set: Average loss: 0.0106, Accuracy: 8894/10000 (89%)\n",
      "\n",
      "[INFO] Saving to ./model/10.pth\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.210337\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.209341\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.344431\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.204968\n",
      "\n",
      "Test set: Average loss: 0.0115, Accuracy: 8894/10000 (89%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.241813\n",
      "Train Epoch: 11 [16000/60000 (27%)]\tLoss: 0.247327\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.109992\n",
      "Train Epoch: 11 [48000/60000 (80%)]\tLoss: 0.175314\n",
      "\n",
      "Test set: Average loss: 0.0111, Accuracy: 8827/10000 (88%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.137041\n",
      "Train Epoch: 12 [16000/60000 (27%)]\tLoss: 0.146979\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.250964\n",
      "Train Epoch: 12 [48000/60000 (80%)]\tLoss: 0.156469\n",
      "\n",
      "Test set: Average loss: 0.0117, Accuracy: 8874/10000 (89%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.144044\n",
      "Train Epoch: 13 [16000/60000 (27%)]\tLoss: 0.242825\n",
      "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 0.240523\n",
      "Train Epoch: 13 [48000/60000 (80%)]\tLoss: 0.154499\n",
      "\n",
      "Test set: Average loss: 0.0130, Accuracy: 8771/10000 (88%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.306015\n",
      "Train Epoch: 14 [16000/60000 (27%)]\tLoss: 0.206347\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.246910\n",
      "Train Epoch: 14 [48000/60000 (80%)]\tLoss: 0.251331\n",
      "\n",
      "Test set: Average loss: 0.0133, Accuracy: 8779/10000 (88%)\n",
      "\n",
      "[INFO] Saving to ./model/15.pth\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.281022\n",
      "Train Epoch: 15 [16000/60000 (27%)]\tLoss: 0.217891\n",
      "Train Epoch: 15 [32000/60000 (53%)]\tLoss: 0.146565\n",
      "Train Epoch: 15 [48000/60000 (80%)]\tLoss: 0.321671\n",
      "\n",
      "Test set: Average loss: 0.0120, Accuracy: 8830/10000 (88%)\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.199432\n",
      "Train Epoch: 16 [16000/60000 (27%)]\tLoss: 0.126831\n",
      "Train Epoch: 16 [32000/60000 (53%)]\tLoss: 0.309105\n",
      "Train Epoch: 16 [48000/60000 (80%)]\tLoss: 0.175474\n",
      "\n",
      "Test set: Average loss: 0.0123, Accuracy: 8815/10000 (88%)\n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.193802\n",
      "Train Epoch: 17 [16000/60000 (27%)]\tLoss: 0.295162\n",
      "Train Epoch: 17 [32000/60000 (53%)]\tLoss: 0.206360\n",
      "Train Epoch: 17 [48000/60000 (80%)]\tLoss: 0.177643\n",
      "\n",
      "Test set: Average loss: 0.0135, Accuracy: 8820/10000 (88%)\n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.159631\n",
      "Train Epoch: 18 [16000/60000 (27%)]\tLoss: 0.196697\n",
      "Train Epoch: 18 [32000/60000 (53%)]\tLoss: 0.134071\n",
      "Train Epoch: 18 [48000/60000 (80%)]\tLoss: 0.209076\n",
      "\n",
      "Test set: Average loss: 0.0134, Accuracy: 8877/10000 (89%)\n",
      "\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.132994\n",
      "Train Epoch: 19 [16000/60000 (27%)]\tLoss: 0.133715\n",
      "Train Epoch: 19 [32000/60000 (53%)]\tLoss: 0.145431\n",
      "Train Epoch: 19 [48000/60000 (80%)]\tLoss: 0.196970\n",
      "\n",
      "Test set: Average loss: 0.0135, Accuracy: 8801/10000 (88%)\n",
      "\n",
      "[INFO] Saving to ./model/20.pth\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "# 模型xunlian\n",
    "model.train(train_loader,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = FashionMnistModel()\n",
    "# 加载权重\n",
    "state_dict = torch.load(\"./model/15.pth\")\n",
    "model2.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FashionMnistModel(\n",
       "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=800, out_features=500, bias=True)\n",
       "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "           'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model,img):\n",
    "    model.eval()\n",
    "    img = img.unsqueeze(dim = 0)\n",
    "    output = model(img)\n",
    "    pred = output.argmax(dim=1, keepdim=True)\n",
    "    return pred.squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img,label = test_dataset.__getitem__(20)\n",
    "pred = inference(model2,img)\n",
    "fig = plt.figure(figsize=(1,1))\n",
    "plt.imshow(np.squeeze(img), cmap='gray')\n",
    "plt.title(label_classes[pred])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
